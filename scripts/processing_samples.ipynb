{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Metadata on Ribo-Seq Studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook the process of parsing outputs from GEO and AR-Geos Searches is documented. This should help reproduce our list of Ribo-Seq studies to be processed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from info_from_pmid import get_info_from_medline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARGEOS (https://ar-geos.org/) is an ArrayExpress and GEO searcher. Through their web portal we provide the below query and recieve a handy output that helps with handling strange meta-information. \n",
    "\n",
    "\"Ribosome Profiling\" OR \"Ribo-Seq\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "argeos_path = '../data/argeos_Ribosome_profiling_Human.tsv'\n",
    "\n",
    "argeos = pd.read_csv(argeos_path, sep=\"\\t\")\n",
    "\n",
    "for i in range(len(list(argeos.Accession))):\n",
    "    if argeos.at[i, \"SRA\"] != \"None\":\n",
    "        argeos.at[i, \"SRA\"] = argeos.at[i, \"SRA\"].split(\"=\")[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also broaden our search by using GEO directly. This is because I found that a subset of studies were not picked up by the ARGEOS search. This search is similarly carried out via the web portal searching the GEO DataSets database (GDS: https://www.ncbi.nlm.nih.gov/gds). \n",
    "\n",
    "\"Ribosome Profiling\" OR \"Ribo-Seq\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_ribosome_profiling_path = '../data/geo_ribosomeprofiling.tsv'\n",
    "\n",
    "geo_ribosome_profiling = pd.read_csv(geo_ribosome_profiling_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration of Inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_accessions = []\n",
    "for i in list(geo_ribosome_profiling.Accession):\n",
    "    if i not in all_accessions:\n",
    "        all_accessions.append(i)\n",
    "\n",
    "for i in list(argeos.Accession):\n",
    "    if i not in all_accessions:\n",
    "        all_accessions.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "492"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_accessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation of Superset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "on = [\"Accession\", \"Title\", \"Organism\", \"Samples\", \"SRA\", \"Release_Date\", \"Organism\"]\n",
    "superset = pd.merge(geo_ribosome_profiling, argeos, how='outer', on=on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Type']\n",
    "index = [i for i, row in superset.iterrows()]\n",
    "type_df = pd.DataFrame(index=index, columns=columns)\n",
    "for i, row in superset.iterrows():\n",
    "    if str(row['Type_x']) != 'nan':\n",
    "        type_df.at[i, 'Type'] = str(row['Type_x'])\n",
    "    else:\n",
    "        type_df.at[i, 'Type'] = str(row['Type_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "superset = pd.concat([superset, type_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in superset.columns:\n",
    "    if 'Type_' in col:\n",
    "        del superset[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import validators \n",
    "\n",
    "columns = ['GSE', 'GSE_Supplementary', 'BioProject']\n",
    "index = [i for i, row in superset.iterrows()]\n",
    "link_df = pd.DataFrame(index=index, columns=columns)\n",
    "\n",
    "gse_supp_base = 'ftp://ftp.ncbi.nlm.nih.gov/geo/series/'\n",
    "gse_base = \"https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=\"\n",
    "\n",
    "for i, row in superset.iterrows():\n",
    "    if str(row['Supplementary Links']) != 'nan':\n",
    "        links = superset.at[i, 'Supplementary Links'].split(';')\n",
    "        for link in links: \n",
    "            if \"GSE\" in link:\n",
    "                gse_accession = link.split('/')[-2]\n",
    "\n",
    "                link_df.at[i, 'GSE_Supplementary'] = link\n",
    "                link_df.at[i, 'GSE'] = gse_base + gse_accession\n",
    "            elif \"PRJ\" in link:\n",
    "                link_df.at[i, \"BioProject\"] = link\n",
    "\n",
    "\n",
    "    else:\n",
    "        if \"GSE\" in row['Link']:\n",
    "            gse_accession = row['Link'].split('=')[-1]\n",
    "            link_df.at[i, 'GSE'] = row['Link']\n",
    "            link_df.at[i, 'BioProject'] = row['BioProject link (NCBI)']\n",
    "            if validators.url(gse_supp_base + gse_accession[:5] + \"nnn/\" + gse_accession + \"/suppl\"):\n",
    "                link_df.at[i, 'GSE_Supplementary'] = gse_supp_base + gse_accession[:-3] + \"nnn/\" + gse_accession + \"/suppl\"\n",
    "            else: \n",
    "                link_df.at[i,'GSE_Supplementary'] = \"\"\n",
    "\n",
    "        else:\n",
    "            link_df.at[i,'GSE'] = \"\"\n",
    "            link_df.at[i,'GSE_Supplementary'] = \"\"\n",
    "            link_df.at[i,'BioProject'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "superset = pd.concat([superset, link_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in superset.columns:\n",
    "    if col in ['Link', \n",
    "    'Supplementary Links', \n",
    "    'Supplementary Types', \n",
    "    'BioProject link (NCBI)', \n",
    "    'BioProject link (EBI)', \n",
    "    'All References', \n",
    "    'Platform', \n",
    "    'Type of molecule', \n",
    "    'Impact factor 2018', \n",
    "    'Summary'\n",
    "    ]:\n",
    "        del superset[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [i for i, row in superset.iterrows()]\n",
    "\n",
    "paper_info_df = pd.DataFrame(columns=[\"PMID\", \"authors\", \"abstract\", \"title\", \"doi\", \"date_published\", \"PMC\", \"journal\"], index=index)\n",
    "for i, row in superset.iterrows():\n",
    "    if str(row['PubMed ID']) != \"nan\":\n",
    "        if paper_info_df.at[i, 'PMID'] != \"nan\":\n",
    "            if len(str(row['PubMed ID'])) > 0:  \n",
    "                info_dict = get_info_from_medline(row['PubMed ID'])\n",
    "                for item in info_dict:\n",
    "                    paper_info_df.at[i, item] = info_dict[item]\n",
    "    else:\n",
    "        if str(row['doi or pubmed id']) != \"nan\":\n",
    "            if \"doi\" in row['doi or pubmed id']:\n",
    "                query = row['doi or pubmed id'].split('doi.org/')[-1]\n",
    "\n",
    "                if len(str(query)) > 0:      \n",
    "                    info_dict = get_info_from_medline(query)\n",
    "                    for item in info_dict:\n",
    "                        paper_info_df.at[i, item] = info_dict[item]\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_info_df.to_csv(\"data/ribo_seq_paper_info.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "superset = pd.concat([superset, paper_info_df], axis=1)\n",
    "\n",
    "for col in superset.columns:\n",
    "    if col in ['PubMed ID', 'doi or pubmed id', 'All references', 'Journal', 'Contact']:\n",
    "        del superset[col] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "superset.to_csv(\"data/ribosome_profiling_superset.tsv\", sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "59ac764984914fe8e0c657f22a743f4cd4d844eddc087eb14206854eff6f21cf"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
